<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>The Challenge Of ReID</title>
    <link href="/2020/05/23/The-Challenge-Of-ReID/"/>
    <url>/2020/05/23/The-Challenge-Of-ReID/</url>
    
    <content type="html"><![CDATA[<p><a href="https://github.com/keenJMS/Person-re-identification/blob/master/%E7%BB%BC%E8%BF%B0/%E5%9F%BA%E4%BA%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E8%A1%8C%E4%BA%BA%E9%87%8D%E8%AF%86%E5%88%AB%E7%A0%94%E7%A9%B6%E8%BF%9B%E5%B1%95.pdf" target="_blank" rel="noopener">文献链接</a><br>(1)跨视角造成的姿态多变问题: 由于不同摄像头架设的角度、 位置不一, 拍摄图片中的行人姿态也十分多变. 目前已经有不少代表性的工作从不同角度上来解决这个问题, 而这些方法主要是依靠一个预训练的姿态模型来实现姿态的对齐.<br>(2)行人图片分辨率变化: 由于摄像头中目标拍摄距离不一致, 拍摄的行人图片分辨率也不一样.这方面方法比较少，已知的有sing方法。<strong>SING</strong>先用高分辨率图片降采样得到一批低分辨率图片. 之后, 网络优化联合学习图像超分辨的重构损失和行人身份识别损失函数. 低分辨率图片经过网络高分辨率处理后再进行特征提取, 而正常分辨率图像则是直接进行特征提取. 由于不同分辨率的图片经过不同的方式提取特征, 因此 SING 网络能够较好地应对分辨率变化的问题.<br>(3)行人图片遮挡问题: 目前学术界的行人重识别数据集大多数清洗过的高质量图像. 然而在真实的使用场景, 行人经常会被移动目标或者静态物体遮挡, 造成行人图片的不完整. 由于失去了部分行人特征而引入了很多干扰特征, 使得很多基于全局特征的行人重识别算法效果大大下降. 一个思路是利用行人姿态模型来估计行人图像的可视部分, 然后对可视部分进行局部特征提取、 融合.<br>(4)图像域变化的跨模态重识别. 图像域的变化是行人重识别应用上非常普遍的一个挑战. 图像域变化的类型也多种多样, 例如不同相机、 不同天气、不同时间、 不同城市拍摄的图像风格均可能不同. 此外, 夜晚 RGB 相机也会失效, 使用红外相机拍摄的图片没有颜色信息, 因此 RGB 图片与红外图片的行人重识别也是个典型的跨模态问题. 目前基于 GAN网络生成图像来解决图像域偏差是一个很流行的思路。</p>]]></content>
    
    
    <categories>
      
      <category>science</category>
      
    </categories>
    
    
    <tags>
      
      <tag>ReID</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>行人再识别技术综述</title>
    <link href="/2020/05/22/%E8%A1%8C%E4%BA%BA%E5%86%8D%E8%AF%86%E5%88%AB%E6%8A%80%E6%9C%AF%E7%BB%BC%E8%BF%B0/"/>
    <url>/2020/05/22/%E8%A1%8C%E4%BA%BA%E5%86%8D%E8%AF%86%E5%88%AB%E6%8A%80%E6%9C%AF%E7%BB%BC%E8%BF%B0/</url>
    
    <content type="html"><![CDATA[<p><a href="https://github.com/keenJMS/Person-re-identification/blob/master/%E7%BB%BC%E8%BF%B0/%E8%A1%8C%E4%BA%BA%E5%86%8D%E8%AF%86%E5%88%AB%E6%8A%80%E6%9C%AF%E7%BB%BC%E8%BF%B0.pdf" target="_blank" rel="noopener">文献链接</a></p><h1 id="1-引言"><a href="#1-引言" class="headerlink" title="1.引言"></a>1.引言</h1><h2 id="1-1什么是行人重识别"><a href="#1-1什么是行人重识别" class="headerlink" title="1.1什么是行人重识别"></a>1.1什么是行人重识别</h2><p>行人再识别 (Person re-identiflcation, Re-ID)起源于多摄像头跟踪, 用于判断非重叠视域中拍摄到的不同图像中的行人是否属于同一个人。广泛应用于智能视频监控、安保等领域。行人图像的分辨率变化大、拍摄角度不统一、光照条件差、环境变化大、行人姿态不断变化等原因,使得行人再识别成为目前计算机视觉领域一个既具有研究价值又极具挑战性的研究热点和难点问题。<br>行人再识别典型流程如下，对于摄像头 A 和 B 采集的图像/视频, 首先进行行人检测, 得到行人图像.为了消除行人检测效果对再识别结果的影响。大部分行人再识别算法使用已经裁剪好的行人图像作为输入。然后针对输入图像中提取稳定、鲁棒的特征,得能够描述和区分不同行人的特征表达向量.最后根据特征表达向量进行相似性度量, 按照相似性大小对图像进行排序, 相似度最高的图像将作为最终的识别结果。<br><img src="/img/%E7%BB%BC%E8%BF%B01.jpg" srcset="/img/loading.gif" alt="综述1"><br>特征提取与表达.从行人外观出发,提取鲁棒性强且具有较强区分性的特征表示向量,有效表达行人图像的特性; 2)相似性度量. 通过特征向量之间的相似度比对, 判断行人的相似性。可以看出, 行人再识别与图像检索的思路相同, 可以看作是图像检索的子问题。</p><h1 id="2-基于人工设计特征的行人再识别"><a href="#2-基于人工设计特征的行人再识别" class="headerlink" title="2.基于人工设计特征的行人再识别"></a>2.基于人工设计特征的行人再识别</h1><h2 id="2-1特征提取与表达"><a href="#2-1特征提取与表达" class="headerlink" title="2.1特征提取与表达"></a>2.1特征提取与表达</h2><h3 id="2-1-1低层视觉特征"><a href="#2-1-1低层视觉特征" class="headerlink" title="2.1.1低层视觉特征"></a>2.1.1低层视觉特征</h3><p>颜色特征：颜色直方图、颜色矩、颜色相关图、颜色聚合向量。<br>纹理特征：纹理特征涉及到相邻像素的比较, 对光照具有鲁棒性。<br>图像分割方法：行人再识别方法在颜色和纹理特征中加入空间区域信息。行人图像被分成多个重叠或非重叠的局部图像块, 然后分别从中提取颜色或纹理特征, 从而为行人特征增加空间区域信息。<br><img src="/img/%E7%BB%BC%E8%BF%B02.jpg" srcset="/img/loading.gif" alt="综述2"><br><img src="/img/%E7%BB%BC%E8%BF%B03.jpg" srcset="/img/loading.gif" alt="综述3"><br>低层特征的提取不需要复杂的训练过程, 可解释性较强. 但是表达能力较弱, 面对复杂的识别环境其泛化能力受到一定制约, 无法针对具体的行人再识别任务进行优化。  </p><h3 id="2-1-2中层滤波器特征"><a href="#2-1-2中层滤波器特征" class="headerlink" title="2.1.2中层滤波器特征"></a>2.1.2中层滤波器特征</h3><p>中层滤波器特征是利用聚类算法, 从行人图像中学习出一系列有表达能力的滤波器. 每一个滤波器都代表一种与身体特定部位相关的视觉模式,也称显著区域 (Salient region).<br><img src="/img/%E7%BB%BC%E8%BF%B04.jpg" srcset="/img/loading.gif" alt="综述4"><br>人体由各个身体部位组成, 具有良好的结构特性, 使用与人体部位对应的滤波器特征能够平衡行人描述符的区分能力和泛化能力. 低层和中层特征结合起来使用能够充分发挥各自的优势, 在一定程度上克服行人再识别中的光照和视角变化问题. 但是, 人体是非刚性目标, 外观易受到姿态、 遮挡等各种因素的影响, 仅利用低层和中层特征会导致识别精度不高, 还需要利用其他更高层的特征.  </p><h3 id="2-1-3高层属性特征"><a href="#2-1-3高层属性特征" class="headerlink" title="2.1.3高层属性特征"></a>2.1.3高层属性特征</h3><p>人类在辨识行人时会使用离散而精确的特有属性 (Attribute)，例如服装样式、 性别、 胖瘦等都属于行人的属性特征. 行人图像对应的属性特征通常采用离散的二进制向量表示形式.与其他特征相比, 高层属性特征尽管在提取和表达方面复杂,属性标定需要大量的人工和时间成本, 但含有更加丰富的语义信息, 而且对于光照和视角变化具有更强的鲁棒性. 因此, 属性特征与低层特征联合使用,可以有效提高识别性能.</p><h3 id="2-1-4视频时空特征"><a href="#2-1-4视频时空特征" class="headerlink" title="2.1.4视频时空特征"></a>2.1.4视频时空特征</h3><p>在基于视频的行人再识别中, 每个行人至少包含两段跨视域的视频序列, 其中包含数量不等的视频帧. 这些视频帧能够提供大量的训练样本, 可以更方便地训练机器学习算法, 从而提高识别的性能.<br>最常用的方法是提取每一帧的低层特征, 然后利用平均/最大池化方法将其聚合为一个全局特征向量, 用以反映行人的外观信息。<br>时空特征反映了视频中的运动信息,是行人外观特征的有效补充. 然而, 时空特征易受视角、 尺度和速度等因素的影响, 在新型的大型行人再识别数据集上表现得差强人意.</p><h2 id="2-2相似性度量"><a href="#2-2相似性度量" class="headerlink" title="2.2相似性度量"></a>2.2相似性度量</h2><p>  根据提取出的特征之间的相似性，判断行人图像是否为同一个人.选择合适的相似性度量方法对行人再识别<br>至关重要. 根据度量过程中是否使用标签, 相似性度量可以分为无监督度量和监督度量.</p><h3 id="2-2-1无监督度量"><a href="#2-2-1无监督度量" class="headerlink" title="2.2.1无监督度量"></a>2.2.1无监督度量</h3><p>无监督度量直接利用特征表达阶段获得的特征向量进行相似性度量. 特征向量之间的相似性往往通过特征向量之间的距离进行度量, 特征向量之间的距离越小, 说明行人图像越相似.比如<strong>欧式距离，巴氏距离</strong>等，这类的缺点是将特征向量的每个维度都等同看待，但实际中每个维度的重要性是不同的。</p><h3 id="2-2-2监督度量"><a href="#2-2-2监督度量" class="headerlink" title="2.2.2监督度量"></a>2.2.2监督度量</h3><p>距离度量学习是基于成对约束的监督度量方法,基本思路是利用给定的训练样本集学习得到一个能够有效反映数据样本间相似度的度量矩阵, 在减少同类样本之间距离的同时, 增大非同类样本之间的距离. 当特征向量提供的信息足够充足时, 距离度量能够获得比非监督方式更高的区分能力. 但是, 与非监督度量方法相比, 距离度量学习需要额外的学习过程, 在训练样本不足时容易产生过拟合现象, 且图像库和场景变化时需要重新训练.<br>常用<strong>马氏距离</strong>。</p><h1 id="3-基于深度学习的行人再识别"><a href="#3-基于深度学习的行人再识别" class="headerlink" title="3.基于深度学习的行人再识别"></a>3.基于深度学习的行人再识别</h1><p>深度学习与传统方法的最大不同在于其特征是从大数据中自动学习得到的, 通过建立类似于人脑的分层模型结构, 能够从大量数据中逐级提取由底层到高层的特征, 获得适合于分类或者识别的深度特征.<br>一个涌入ReID的深度神经网络一般包含卷积层(提取图像的各种信息, 例如边缘和形状)、池化层(对卷积后的特征信号进行抽象, 从而大幅减少训练参数, 另外还可以减少过拟合现象的出现)和全连接层(将池化层得到的特征图投影到一维的特征空间, 形成行人图像的特征向量)，如下图所示：<br><img src="/img/%E7%BB%BC%E8%BF%B05.jpg" srcset="/img/loading.gif" alt="综述5"><br>首先将不同视域中的行人图像作为网络的输入, 然后将这些图像分解为不同的颜色通道子图分别进行处理. 对于每幅子图, 在接下来的卷积层中对其实施卷积滤波操作, 得到不同局部图像块的响应, 作为局部特征. 这些局部特征组合起来, 形成特征图, 作为该卷积层的输出.<br>深度学习模型可以将特征表达和相似度量两个环节整合在一起，按整合方式的不同可分为<strong>端到端、混合式和独立式</strong>.<br><img src="/img/%E7%BB%BC%E8%BF%B06.jpg" srcset="/img/loading.gif" alt="综述6"></p><h2 id="3-1端到端式的深度行人再识别"><a href="#3-1端到端式的深度行人再识别" class="headerlink" title="3.1端到端式的深度行人再识别"></a>3.1端到端式的深度行人再识别</h2><p>端到端式的行人再识别利用深度学习模型, 将特征提取和相似性度量这两个主要环节整合到一个统一的框架下进行联合优化, 形成一种端到端的行人再识别方案.<strong>Siamese网络，递归神经网络RNN,长短期记忆网络LSTM</strong><br>早期的端到端方法在进行相似性比较时, 往往采用简单的欧氏距离或余弦距离, 缺少距离学习的过程, 影响了识别准确率. 常见的解决方法是在深度网络训练过程中加入损失函数约束, 使得同类样本距离变小, 异类样本距离变大, 达到距离学习的效果.</p><h2 id="3-2混合式的深度行人再识别"><a href="#3-2混合式的深度行人再识别" class="headerlink" title="3.2混合式的深度行人再识别"></a>3.2混合式的深度行人再识别</h2><p>该方法可以采用较为成熟的人工特征表达行人的局部特性, 采用浅层的网络结构提取行人的全局特征, 二者结合可以充分发挥各自优势, 在一定程度上弥补训练数据的不足, 同时可以在一定程度上避免深度网络模型过于复杂、 网络训练速度慢的缺点.  </p><h2 id="3-3独立式的深度行人再识别"><a href="#3-3独立式的深度行人再识别" class="headerlink" title="3.3独立式的深度行人再识别"></a>3.3独立式的深度行人再识别</h2><p>独立式的深度行人再识别方法的框架与基于人工特征的方法相似, 不同的是采用深度神经网络提取行人图像的深度特征, 然后结合距离度量学习方法完成行人再识别.基于深度学习的行人再识别方法仅经过极少的预处理就可以得到从原始像素到高层语义的有效特征表达. 另外, 在行人图像中, 各种复杂的因素, 包括姿态、 性别、 着装等, 往往以非线性的方式组合在一起, 而深度学习可以通过多层非线性映射将这些因素分开, 利用不同的神经元代表不同因素, 使其变成简单的线性关系, 不再相互影响, 从而提升识别效果.</p><h1 id="4-数据集"><a href="#4-数据集" class="headerlink" title="4.数据集"></a>4.数据集</h1><p><img src="%5Cimg%5C%E6%95%B0%E6%8D%AE%E9%9B%86.jpg" srcset="/img/loading.gif" alt="数据集"><br>VIPeR、 CUHK01 和 Market-1501 均为基于图像的行人再识别数据集.PRID-2011、 iLIDS-VID 和 MARS 均为基于视频的行人再识别数据集.<br>累计匹配性能曲线 (Cumulative match characteristic, CMC) 和 Rank-N 表格.  常见的有 Rank-1, Rank-5,Rank-10 和 Rank-20. 其中 Rank-5 代表在前 5 幅图像中可以正确匹配的概率, 概率值越大表示效果<br>越好.<br><img src="%5Cimg%5CRANKN.jpg" srcset="/img/loading.gif" alt="RANKN">    </p><h1 id="5-展望"><a href="#5-展望" class="headerlink" title="5.展望"></a>5.展望</h1><p>未来的发展方向有：长时间的行人再识别，结合多模态生物线索的行人再识别.密集场景与低分辨率环境下的行人再识别。设计鲁棒的语义级行人特征表达.基于深度属性的行人再识别. </p>]]></content>
    
    
    <categories>
      
      <category>science</category>
      
    </categories>
    
    
    <tags>
      
      <tag>ReID</tag>
      
      <tag>Summary</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hello World</title>
    <link href="/2020/05/21/hello-world/"/>
    <url>/2020/05/21/hello-world/</url>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="This-is-my-blog"><a href="#This-is-my-blog" class="headerlink" title="This is my blog"></a>This is my blog</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><pre><code class="hljs bash">$ hexo new <span class="hljs-string">"My New Post"</span></code></pre><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><pre><code class="hljs bash">$ hexo server</code></pre><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><pre><code class="hljs bash">$ hexo generate</code></pre><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><pre><code class="hljs bash">$ hexo deploy</code></pre><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
